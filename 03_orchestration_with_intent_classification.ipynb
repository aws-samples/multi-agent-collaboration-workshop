{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c12918a0",
   "metadata": {},
   "source": [
    "# Use Intent Classification to orchestrate multiple sub-agents "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcecc32",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In the hierarchical model of multi-agent collaboration, an alternative approach to using a supervisor agent is employing a Large Language Model (LLM) for intent classification and request routing. This method leverages the LLM's natural language understanding capabilities to analyze user inputs and determine which specialized agent should handle the request. For instance, in a mortgage services scenario, the LLM can distinguish between payment processing and loan application inquiries, directing them to the appropriate agent. This approach streamlines the interaction flow, reducing the need for complex decision-making hierarchies and allowing for more flexible and scalable system architecture.\n",
    "\n",
    "In this notebook, you will see how we can use the LLM intent classification to route requests to the two previous agents you built in [01_create_agents_and_kbs.ipynb](./01_create_agents_and_kbs.ipynb). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa67d7a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First step is to install the pre-requisites packages. NOTE: You only need to do this is this is the first notebook you are running. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ac05c073-d45b-4d85-9bf8-ae10aa78be8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade -q -r requirements.txt\n",
    "# !pip install --upgrade -q boto3 botocore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ad6ec2-b283-4c5d-879f-e397e46568c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import boto3\n",
    "import logging\n",
    "import pprint\n",
    "import json\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from agent import AgentsForAmazonBedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b2d607-c1f2-4cbb-9f89-d935676e0101",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Clients\n",
    "s3_client = boto3.client('s3')\n",
    "sts_client = boto3.client('sts')\n",
    "session = boto3.session.Session()\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "bedrock_agent_client = boto3.client('bedrock-agent')\n",
    "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime')\n",
    "\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d647d2a3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "region = session.region_name\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "\n",
    "suffix = f\"{region}-{account_id}\"\n",
    "bucket_name = f'mac-workshop-{suffix}'\n",
    "agent_foundation_models = [\n",
    "    \"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    \"anthropic.claude-3-sonnet-20240229-v1:0\", \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31994238",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = AgentsForAmazonBedrock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3715525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_agent_names = [\"existing_mortgage_agent\", \"mortgage_application_agent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8deade1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyIntentByLLM(input_text, bedrock_runtime, model_id, \n",
    "                        top_p=1, temp=0, system=''):  \n",
    "    messages = [\n",
    "        {\n",
    "        \"role\": 'user',\n",
    "        \"content\": [ {\"type\": \"text\", \"text\":\n",
    "f\"\"\"\n",
    "You will be given some user input. Classify that input according to which bot would be\n",
    "the most appropriate one to respond that input.\n",
    "\n",
    "EXISTING: can retrieve the latest information about an existing mortgage, like principal balance and\n",
    "payment information.\n",
    "\n",
    "APPLICATION: handle requests related to mortgage applications that are in process. creating, managing, \n",
    "and completing these mortgage applications. help find status of required application documentation.\n",
    "assumes that the mortgage type is already determined. unable to handle general questions about mortgages\n",
    "like tradeoffs between different mortgage types.\n",
    "\n",
    "MORTGAGE_TYPE_KB: handle general mortgage questions about different mortgage types like comparing 15-year vs 30-year\n",
    "\n",
    "OTHER: not applicable for any of the bots available.\n",
    "\n",
    "Here is the user input text:\n",
    "<input_text>\n",
    "{input_text}\n",
    "</input_text>\n",
    "\n",
    "Return only the name of the bot, with no preamble.\n",
    "\"\"\"\n",
    "        }]\n",
    "        }\n",
    "    ]  \n",
    "    body=json.dumps(\n",
    "        {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 25,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": temp,\n",
    "            \"top_p\": top_p,\n",
    "            \"system\": system,\n",
    "            \"stop_sequences\":[\"assistant\"]\n",
    "        }  \n",
    "    )  \n",
    "    \n",
    "    response = bedrock_runtime.invoke_model(body=body, modelId=model_id)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    # print(response_body)\n",
    "    \n",
    "    return response_body['content'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52812ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifyIntentByLLM(\"what is the status of my application?\", bedrock_client, \n",
    "                model_id = \"anthropic.claude-3-haiku-20240307-v1:0\", temp=0.5, top_p=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c19f23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifyIntentByLLM(\"what is better, 30 year mortgage or 15 year?\", bedrock_client, \n",
    "                model_id = \"anthropic.claude-3-haiku-20240307-v1:0\", temp=0.5, top_p=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ae63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifyIntentByLLM(\"why would I pick a 15 year mortgage over a 30 year?\", bedrock_client, \n",
    "                model_id = \"anthropic.claude-3-haiku-20240307-v1:0\", temp=0.5, top_p=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c0e3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifyIntentByLLM(\"what is the status of the documents I need to provide?\", bedrock_client, \n",
    "                model_id = \"anthropic.claude-3-haiku-20240307-v1:0\", temp=0.5, top_p=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd94515",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifyIntentByLLM(\"when is my next payment due?\", bedrock_client, \n",
    "                model_id = \"anthropic.claude-3-haiku-20240307-v1:0\", temp=0.5, top_p=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53dc47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifyIntentByLLM(\"I am customer 288. What is my existing balance?\", bedrock_client, \n",
    "                model_id = \"anthropic.claude-3-haiku-20240307-v1:0\", temp=0.5, top_p=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e49644",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTENT_TO_ID_MAP = {\n",
    "    \"EXISTING\": agents.get_agent_id_by_name(\"existing_mortgage_agent\"),\n",
    "    \"APPLICATION\": agents.get_agent_id_by_name(\"mortgage_application_agent\")\n",
    "}\n",
    "INTENT_TO_ID_MAP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7923dc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from knowledge_base import BedrockKnowledgeBaseHelper\n",
    "helper = BedrockKnowledgeBaseHelper()\n",
    "kb_id = helper.get_kb()\n",
    "kb_arn = f\"arn:aws:bedrock:{region}:{account_id}:knowledge-base/{kb_id}\"\n",
    "\n",
    "print(kb_id)\n",
    "print(kb_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "526ba5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invokeByIntent(input_text, session_id, session_state={}):\n",
    "    input_intent = classifyIntentByLLM(input_text, bedrock_client, \n",
    "                            model_id = \"anthropic.claude-3-haiku-20240307-v1:0\", temp=0.5, top_p=0.9)\n",
    "\n",
    "    if input_intent == \"EXISTING\":\n",
    "        # print('invoking Existing Mortgage agent...')\n",
    "        response = agents.invoke(input_text, INTENT_TO_ID_MAP[\"EXISTING\"], \n",
    "                                              session_id=session_id, session_state=session_state)\n",
    "    elif input_intent == \"APPLICATION\":\n",
    "        # print('invoking Mortgage Application agent...')\n",
    "        response = agents.invoke(input_text, INTENT_TO_ID_MAP[\"APPLICATION\"], \n",
    "                                              session_id=session_id, session_state=session_state)\n",
    "    elif input_intent == \"MORTGAGE_TYPE_KB\":\n",
    "        rag_response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "            input={\n",
    "                    \"text\": input_text\n",
    "                },\n",
    "            retrieveAndGenerateConfiguration={\n",
    "                    \"type\": \"KNOWLEDGE_BASE\",\n",
    "                    \"knowledgeBaseConfiguration\": {\n",
    "                        'knowledgeBaseId': kb_id,\n",
    "                        \"modelArn\": f\"arn:aws:bedrock:{region}::foundation-model/{agent_foundation_models[0]}\",\n",
    "                        \"retrievalConfiguration\": {\n",
    "                            \"vectorSearchConfiguration\": {\n",
    "                                \"numberOfResults\":5\n",
    "                            } \n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "        response = rag_response['output']['text']\n",
    "    else:\n",
    "        response = \"Sorry, I don't have that expertise. Please ask a different question.\"\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffe5aac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_session_id = '999'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45453ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(invokeByIntent(\"my id is 8953. when is my payment due?\", sup_session_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd4352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "invokeByIntent(\"compare and contrast 15-year vs 30-year mortgage type\", sup_session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28ef0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "invokeByIntent(\"I am customer 948. what documents do i still need to provide for my application?\", \n",
    "                sup_session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "invokeByIntent(\"what documents have i already provided for my application?\", sup_session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270c16a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "invokeByIntent(\"my ID is 9856. what is my principal balance on my existing mortgage?\", \n",
    "            sup_session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050ffb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "invokeByIntent(\"my customer id is 8953. when is my payment due?\", sup_session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895a63a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "invokeByIntent(\"what considerations are there when deciding on a 30 year mortage?\", sup_session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7043ba4",
   "metadata": {},
   "source": [
    "##### Invoke Agent by Intent, with prompt attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd8e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "today = datetime.today().strftime('%b-%d-%Y')\n",
    "\n",
    "session_state = {\n",
    "    \"promptSessionAttributes\": {\n",
    "        \"customer_ID\": \"498\",\n",
    "        \"today\": today\n",
    "    }\n",
    "}\n",
    "session_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139c210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sup_session_id = \"111\"\n",
    "print(invokeByIntent(\"what docs do I still owe you?\", \n",
    "                    sup_session_id, session_state=session_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822d9a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sup_session_id = \"222\"\n",
    "print(invokeByIntent(\"how many years until I reach the mortgage maturity date?\", \n",
    "                        sup_session_id, session_state=session_state))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2e5a47",
   "metadata": {},
   "source": [
    "### Quick performance test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6fa1b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid \n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def query_loop_by_intent(query, num_invokes):\n",
    "    latencies = []\n",
    "    for i in range(num_invokes):\n",
    "        _session_id = str(uuid.uuid1())\n",
    "        _start_time = time.time()\n",
    "        resp = invokeByIntent(query, _session_id)\n",
    "        _end_time = time.time()\n",
    "        latencies.append(_end_time - _start_time)\n",
    "\n",
    "    print(f'\\n\\nInvoked by intent {num_invokes} times.')\n",
    "    # get sum of total latencies\n",
    "    total_time = sum(latencies)\n",
    "    # get average latency\n",
    "    avg_time = total_time / num_invokes\n",
    "    # get p90 latency\n",
    "    p90_time = np.percentile(latencies, 90)\n",
    "\n",
    "    print(f'Average latency: {avg_time:.1f}, P90 latency: {p90_time:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f817c809",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_loop_by_intent(\"I am customer 999. how many years until the mortgage maturity date?\", 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5e9f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid \n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def classification_loop(query, num_invokes, runtime, model):\n",
    "    latencies = []\n",
    "    for i in range(num_invokes):\n",
    "        _session_id = str(uuid.uuid1())\n",
    "        _start_time = time.time()\n",
    "        resp = classifyIntentByLLM(query, runtime, model)\n",
    "        _end_time = time.time()\n",
    "        latencies.append(_end_time - _start_time)\n",
    "\n",
    "    print(f'\\n\\nClassified by intent {num_invokes} times.')\n",
    "    # get sum of total latencies\n",
    "    total_time = sum(latencies)\n",
    "    # get average latency\n",
    "    avg_time = total_time / num_invokes\n",
    "    # get p90 latency\n",
    "    p90_time = np.percentile(latencies, 90)\n",
    "\n",
    "    print(f'Average latency: {avg_time:.1f}, P90 latency: {p90_time:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4828c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_loop(\"I'm customer 99. what's my balance?\", 25, \n",
    "                    bedrock_client, agent_foundation_models[0])"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
