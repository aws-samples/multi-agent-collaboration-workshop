{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c12918a0",
   "metadata": {},
   "source": [
    "# Use Function Calling / Tool Use to orchestrate sub-agents and knowledge bases "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcecc32",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Function calling is another powerful approach to orchestrate multi-agent collaboration within a hierarchical model. This method involves providing the primary Large Language Model (LLM) with a set of predefined functions that represent the capabilities of various sub-agents and knowledge bases. The LLM can then decide which function to call based on the user's input and the task at hand. This approach allows for more structured and controlled interactions between the main orchestrator and its sub-components, ensuring that each specialized agent or knowledge base is utilized effectively.\n",
    "\n",
    "In this notebook, you will \n",
    "* Use the sub-agents built in [01_create_agents_and_kbs.ipynb](./01_create_agents_and_kbs.ipynb)\n",
    "* Define a tool class and tool specifications\n",
    "* Utilize the Amazon Bedrock Converse API to orchestrate routing and requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa67d7a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First step is to install the pre-requisites packages. NOTE: You only need to do this is this is the first notebook you are running. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac05c073-d45b-4d85-9bf8-ae10aa78be8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade -q -r requirements.txt\n",
    "# !pip install --upgrade -q boto3 botocore awscli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ad6ec2-b283-4c5d-879f-e397e46568c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import logging\n",
    "from typing import List, Dict\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from knowledge_base import BedrockKnowledgeBase\n",
    "from agent import AgentsForAmazonBedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705dd3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d2b2d607-c1f2-4cbb-9f89-d935676e0101",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Clients\n",
    "s3_client = boto3.client('s3')\n",
    "sts_client = boto3.client('sts')\n",
    "bedrock_agent_client = boto3.client('bedrock-agent')\n",
    "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime')\n",
    "\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3348467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = AgentsForAmazonBedrock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d647d2a3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "region = agents.get_region()\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "\n",
    "suffix = f\"{region}-{account_id}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5520818",
   "metadata": {},
   "source": [
    "Identify the list of FMs you'd like to experiment with for function-calling based\n",
    "approach to orchestrating available sub-agents and knowledge bases. \n",
    "Only include models that your account has access to use, and that support Bedrock Converse \n",
    "tool use. The underlying sub-agents will continue to use whichever models they were created with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "cb790f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "foundation_models = [\n",
    "    \"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    \"mistral.mistral-large-2402-v1:0\",\n",
    "    \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "    #\"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "34f41f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_client = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb5ea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from knowledge_base import BedrockKnowledgeBaseHelper\n",
    "helper = BedrockKnowledgeBaseHelper()\n",
    "kb_id = helper.get_kb()\n",
    "kb_arn = f\"arn:aws:bedrock:{region}:{account_id}:knowledge-base/{kb_id}\"\n",
    "\n",
    "print(kb_id)\n",
    "print(kb_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaefb26",
   "metadata": {},
   "source": [
    "Define a class that acts as a pass-through for executing the Tool Use calls that \n",
    "the Bedrock Converse API returns based on the user request. It includes one method for \n",
    "each sub-agent, and one method for knowledge base lookups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "c1676c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MortgageTools:\n",
    "    def __init__(self, session_id: str=\"9999999\", session_state: dict={}, \n",
    "                 mortgage_kb_id: str=kb_id, kb_model_id: str=foundation_models[0]):\n",
    "        self._session_id = session_id\n",
    "        self._session_state = session_state\n",
    "        self._existing_mortgage_agent_id = agents.get_agent_id_by_name('existing_mortgage_agent')\n",
    "        self._mortgage_application_agent_id = agents.get_agent_id_by_name('mortgage_application_agent')\n",
    "        self._kb_model_arn = f\"arn:aws:bedrock:{region}::foundation-model/{kb_model_id}\"\n",
    "        self._mortgage_kb_id = mortgage_kb_id\n",
    "\n",
    "    def invoke_existing_mortgage_agent(self, input_text):\n",
    "        return agents.invoke(input_text, self._existing_mortgage_agent_id,\n",
    "                            session_id=self._session_id, session_state=self._session_state)\n",
    "    def invoke_mortgage_application_agent(self, input_text):\n",
    "        return agents.invoke(input_text, self._mortgage_application_agent_id,\n",
    "                            session_id=self._session_id, session_state=self._session_state)\n",
    "    def perform_kb_lookup(self, input_text):\n",
    "        kb_response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "            input={\"text\": input_text},\n",
    "            retrieveAndGenerateConfiguration={\n",
    "                    \"type\": \"KNOWLEDGE_BASE\",\n",
    "                    \"knowledgeBaseConfiguration\": {\n",
    "                        'knowledgeBaseId': self._mortgage_kb_id,\n",
    "                        \"modelArn\": self._kb_model_arn,\n",
    "                        \"retrievalConfiguration\": {\n",
    "                            \"vectorSearchConfiguration\": {\n",
    "                                \"numberOfResults\":5\n",
    "                            } \n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "        return kb_response['output']['text']\n",
    "    def set_session(self, session_id, session_state: dict={}):\n",
    "        self._session_id = session_id\n",
    "        self._session_state = session_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c334af2",
   "metadata": {},
   "source": [
    "Now test the MortgageTools class directly to ensure it can handle the requests we will\n",
    "later get from Converse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b3c093a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = MortgageTools(\"999\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bd50d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr(tools, \"invoke_existing_mortgage_agent\")(\"I'm customer 99. When's my pmt due?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cdb341",
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr(tools, \"invoke_mortgage_application_agent\")(\"I am customer 99. What docs do I owe you for my existing application?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc58d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr(tools, \"perform_kb_lookup\")(\"compare and contrast 15-year vs 30-year mortgage type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46a17e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "today = datetime.today().strftime('%b-%d-%Y')\n",
    "\n",
    "session_state = {\n",
    "    \"promptSessionAttributes\": {\n",
    "        \"customer_ID\": \"498\",\n",
    "        \"today\": today\n",
    "    }\n",
    "}\n",
    "session_state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a419a65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.set_session(\"893\", session_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed055a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr(tools, \"invoke_existing_mortgage_agent\")(\"what's my balance, and how many years until I'm done w/ this sill mortgage?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fcd6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisor_agent_name = \"mortgage_supervisor_agent\"\n",
    "function_defs = agents.get_function_defs(supervisor_agent_name)\n",
    "function_defs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "30135066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_function_defs_to_tools(function_defs: Dict) -> Dict:\n",
    "    tools = []\n",
    "    for function_def in function_defs:\n",
    "        params_as_properties = {}\n",
    "        required_params = []\n",
    "        for param_name, param_details in function_def[\"parameters\"].items():\n",
    "            params_as_properties[param_name] = {\n",
    "                \"type\": param_details[\"type\"],\n",
    "                \"description\": param_details[\"description\"],\n",
    "            }\n",
    "            if param_details[\"required\"]:\n",
    "                required_params.append(param_name)\n",
    "        tool_def = {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": function_def[\"name\"].replace(\"-\", \"_\"),\n",
    "                \"description\": function_def[\"description\"],\n",
    "                'inputSchema': {\n",
    "                    'json': {\n",
    "                        'type': 'object',\n",
    "                            'properties': params_as_properties,\n",
    "                            'required': required_params\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        tools.append(tool_def)\n",
    "    return tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7f7cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_function_defs_to_tools(function_defs['functions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "aaad773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_agent_tools = map_function_defs_to_tools(function_defs['functions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bcd602",
   "metadata": {},
   "source": [
    "Now create a tool spec for the knowledge base, and assemble the full set of tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f27abddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_tool = {'toolSpec': {'name': 'perform_kb_lookup',\n",
    "   'description': 'handle general mortgage questions about different mortgage types like comparing 15-year vs 30-year',\n",
    "   'inputSchema': {'json': {'type': 'object',\n",
    "     'properties': {'input_text': {'type': 'string',\n",
    "       'description': 'The request to be answered by doing a knowledge base lookup.'}},\n",
    "     'required': ['input_text']}}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5bba2646",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tool_set = []\n",
    "full_tool_set.extend(sub_agent_tools)\n",
    "full_tool_set.append(kb_tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209e5e4b",
   "metadata": {},
   "source": [
    "## Converse API\n",
    "\n",
    "In this lab we will be utilizing the Converse API. You can use the Amazon Bedrock Converse API to create conversational applications that send and receive messages to and from an Amazon Bedrock model. For example, you can create a chat bot that maintains a conversation over many turns and uses a persona or tone customization that is unique to your needs, such as a helpful technical support assistant. The Converse API allows you to utilizes tools with your models. For example, you might have a chat application that lets users find out out the most popular song played on a radio station. To answer a request for the most popular song, a model needs a tool that can query and return the song information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfb9b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "toolConfigGen = {\n",
    "    'tools': full_tool_set,\n",
    "    'toolChoice': {\n",
    "        'auto': {},\n",
    "        }\n",
    "}\n",
    "toolConfigGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "e4b86afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for caling the Bedrock Converse API...\n",
    "def converse_with_tools(messages, system='', model_id=foundation_models[0], \n",
    "                        tool_config=toolConfigGen, bedrock_client=bedrock_client):\n",
    "    response = bedrock_client.converse(\n",
    "        modelId=model_id,\n",
    "        system=system,\n",
    "        messages=messages,\n",
    "        toolConfig=tool_config\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "5ab785f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for orchestrating the conversation flow...\n",
    "def converse(prompt, system=' ', bedrock_client=bedrock_client, \n",
    "             session_id: str=None, tool_config=toolConfigGen,\n",
    "             verbose=False, respond_direct_from_tool=False,\n",
    "             model_id:str=foundation_models[0],\n",
    "             tools: MortgageTools=tools):\n",
    "    #Add the initial prompt:\n",
    "    messages = []\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"text\": prompt\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\n{datetime.now().strftime('%H:%M:%S')} - Initial prompt:\\n{json.dumps(messages, indent=2)}\")\n",
    "\n",
    "    #Invoke the model the first time:\n",
    "    output = converse_with_tools(messages, system, tool_config=tool_config, model_id=model_id)\n",
    "    if verbose:\n",
    "        print(f\"\\n{datetime.now().strftime('%H:%M:%S')} - Output so far:\\n{json.dumps(output['output'], indent=2, ensure_ascii=False)}\")\n",
    "\n",
    "    #Add the intermediate output to the prompt:\n",
    "    messages.append(output['output']['message'])\n",
    "\n",
    "    function_calling = next((c['toolUse'] for c in output['output']['message']['content'] if 'toolUse' in c), None)\n",
    "\n",
    "    #Check if function calling is triggered:\n",
    "    if not function_calling:\n",
    "        return output['output']['message']['content'][0]['text']\n",
    "    else:\n",
    "        #Get the tool name and arguments:\n",
    "        tool_name = function_calling['name']\n",
    "        tool_args = function_calling['input'] or {}\n",
    "        \n",
    "        #Run the tool:\n",
    "        if session_id is not None:\n",
    "            tools.set_session(session_id)\n",
    "        if verbose:\n",
    "            print(f\"\\n{datetime.now().strftime('%H:%M:%S')} - Running ({tool_name}) tool...\")\n",
    "            \n",
    "        tool_response = getattr(tools, tool_name)(**tool_args)\n",
    "\n",
    "        if verbose: \n",
    "            print(tool_response)\n",
    "\n",
    "        if respond_direct_from_tool: \n",
    "            return tool_response\n",
    "        else:\n",
    "            #Add the tool result to the prompt:\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            'toolResult': {\n",
    "                                'toolUseId':function_calling['toolUseId'],\n",
    "                                'content': [\n",
    "                                    {\n",
    "                                        \"text\": tool_response\n",
    "                                    }\n",
    "                                ]\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "            if verbose:\n",
    "                print(f\"\\n{datetime.now().strftime('%H:%M:%S')} - Messages so far:\\n{json.dumps(messages, indent=2)}\")\n",
    "\n",
    "            # Invoke the model one more time:\n",
    "            output = converse_with_tools(messages, system, bedrock_client=bedrock_client, model_id=model_id)\n",
    "            if verbose:\n",
    "                print(f\"\\n{datetime.now().strftime('%H:%M:%S')} - Final output:\\n{json.dumps(output['output'], indent=2, ensure_ascii=False)}\\n\")\n",
    "            if len(output['output']['message']['content']) > 0:\n",
    "                return output['output']['message']['content'][0]['text']\n",
    "            else:\n",
    "                return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db498c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_request = \"I'm customer 99. what's my balance?\"\n",
    "\n",
    "session_id:str = str(uuid.uuid1())\n",
    "output = converse(\n",
    "        system = [{\"text\": \"You are a virtual agent that delegates requests to sub-agents. \"}],\n",
    "        prompt =  \"Instructions: Respond as though you are completing the requests on your own,\" +\\\n",
    "                      \"without mentioning antying about your sub-agents.\" +\\\n",
    "                      \"Always try to use an available tool instead of asking a clarifying question.\"\n",
    "                      f\"User request: {user_request}\",\n",
    "        session_id=session_id,\n",
    "        respond_direct_from_tool=True,\n",
    "        verbose=False,\n",
    "        model_id=foundation_models[0])\n",
    "print(f\"Output: {output}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_request = \"What are the key differences between 15-year and 30-year mortgages?\"\n",
    "\n",
    "session_id:str = str(uuid.uuid1())\n",
    "output = converse(\n",
    "        system = [{\"text\": \"You are a virtual agent that delegates requests to sub-agents. \"}],\n",
    "        prompt =  \"Instructions: Respond as though you are completing the requests on your own,\" +\\\n",
    "                      \"without mentioning antying about your sub-agents.\" +\\\n",
    "                      \"Always try to use an available tool instead of asking a clarifying question.\"\n",
    "                      f\"User request: {user_request}\",\n",
    "        session_id=session_id,\n",
    "        respond_direct_from_tool=True,\n",
    "        verbose=False,\n",
    "        model_id=foundation_models[0])\n",
    "print(f\"Output: {output}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5aca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_request = \"I'm customer 984. What documents do I still owe for my new mortgage application?\"\n",
    "\n",
    "session_id:str = str(uuid.uuid1())\n",
    "output = converse(\n",
    "        system = [{\"text\": \"You are a virtual agent that delegates requests to sub-agents. \"}],\n",
    "        prompt =  \"Instructions: Respond as though you are completing the requests on your own,\" +\\\n",
    "                      \"without mentioning antying about your sub-agents.\" +\\\n",
    "                      \"Always try to use an available tool instead of asking a clarifying question.\"\n",
    "                      f\"User request: {user_request}\",\n",
    "        session_id=session_id,\n",
    "        respond_direct_from_tool=True,\n",
    "        verbose=False,\n",
    "        model_id=foundation_models[0])\n",
    "print(f\"Output: {output}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2861620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_request = \"What is your favorite basketball team?\"\n",
    "\n",
    "session_id:str = str(uuid.uuid1())\n",
    "output = converse(\n",
    "        system = [{\"text\": \"You are a virtual agent that delegates requests to sub-agents. \"}],\n",
    "        prompt =  \"Instructions: Respond as though you are completing the requests on your own,\" +\\\n",
    "                      \"without mentioning antying about your sub-agents.\" +\\\n",
    "                      \"Always try to use an available tool instead of asking a clarifying question.\"\n",
    "                      f\"User request: {user_request}\",\n",
    "        session_id=session_id,\n",
    "        respond_direct_from_tool=True,\n",
    "        verbose=False,\n",
    "        model_id=foundation_models[0])\n",
    "print(f\"Output: {output}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f02972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_request = \"I'm customer 99. what's my balance?\"\n",
    "\n",
    "for m in foundation_models:\n",
    "    print(f\"\\n**** Using function calling via model: {m} ****\")\n",
    "    for i in range(3):\n",
    "        session_id:str = str(uuid.uuid1())\n",
    "        output = converse(\n",
    "            system = [{\"text\": \"You are a virtual agent that delegates requests to sub-agents.\"}],\n",
    "            prompt =  \"Instructions: Respond as though you are completing the requests on your own,\" +\\\n",
    "                      \"without mentioning antying about your sub-agents.\" +\\\n",
    "                      \"Always try to use an available tool instead of asking a clarifying question.\"\n",
    "                      f\"User request: {user_request}\",\n",
    "            session_id=session_id,\n",
    "            respond_direct_from_tool=True,\n",
    "            verbose=False,\n",
    "            model_id=m)\n",
    "        print(f\"{i+1}) Output: {output}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15ffff2",
   "metadata": {},
   "source": [
    "## Quick Performance Test\n",
    "\n",
    "Performance is a consideration when deciding on using a supervisor agent, intent classification, etc. In the below code you will see the impact of function calling where functions will be invoked multiple times to obtain averages for latency for each response to provide you an idea of it's overall impact to performance. Latency will vary based on model types you select for each agent and the integrations you utilize within your AWS Lambda functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "f6752e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid \n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def query_loop_by_function_calling(user_request, num_invokes, fc_model):\n",
    "    latencies = []\n",
    "    for i in range(num_invokes):\n",
    "        _session_id = str(uuid.uuid1())\n",
    "        _start_time = time.time()\n",
    "\n",
    "        _output = converse(\n",
    "            system = [{\"text\": \"You are a virtual agent that delegates requests to sub-agents.\"}],\n",
    "            prompt =  \"Instructions: Respond as though you are completing the requests on your own,\" +\\\n",
    "                      \"without mentioning antying about your sub-agents.\" +\\\n",
    "                      f\"User request: {user_request}\",\n",
    "            session_id=_session_id,\n",
    "            respond_direct_from_tool=True,\n",
    "            verbose=False,\n",
    "            model_id=fc_model)\n",
    "\n",
    "        _end_time = time.time()\n",
    "        latencies.append(_end_time - _start_time)\n",
    "\n",
    "    print(f'\\n\\nInvoked by function calling {num_invokes} times.')\n",
    "    # get sum of total latencies\n",
    "    total_time = sum(latencies)\n",
    "    # get average latency\n",
    "    avg_time = total_time / num_invokes\n",
    "    # get p90 latency\n",
    "    p90_time = np.percentile(latencies, 90)\n",
    "\n",
    "    print(f'Average latency: {avg_time:.1f}, P90 latency: {p90_time:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9d6b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_loop_by_function_calling(\"I am customer 999. how many years until the mortgage maturity date?\", \n",
    "                               25,\n",
    "                               fc_model=foundation_models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc435e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
